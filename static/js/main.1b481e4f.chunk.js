(this["webpackJsonpmy-website"]=this["webpackJsonpmy-website"]||[]).push([[0],{13:function(e){e.exports=JSON.parse('[{"title":"Mapping the organization and dynamics of the posterior medial network during movie watching","authors":"Cooper, R. A., Kurkela, K. A., Davis, S. W., & Ritchey, M.","journal":"NeuroImage, 236, 118075","year":"2021","abstract":"Abstract: Brain regions within a posterior medial network (PMN) are characterized by sensitivity to episodic tasks, and they also demonstrate strong functional connectivity as part of the default network. Despite its cohesive structure, delineating the intranetwork organization and functional diversity of the PMN is crucial for understanding its contributions to multidimensional event cognition. Here, we probed functional connectivity of the PMN during movie watching to identify its pattern of connections and subnetwork functions in a split-sample replication of 136 participants. Consistent with prior findings of default network fractionation, we identified distinct PMN subsystems: a Ventral PM subsystem (retrosplenial cortex, parahippocampal cortex, posterior angular gyrus) and a Dorsal PM subsystem (medial prefrontal cortex, hippocampus, precuneus, posterior cingulate cortex, anterior angular gyrus). These subsystems were anchored by two complementary regions: Retrosplenial cortex mediated communication between parahippocampal cortex and the Dorsal PM system, and posterior cingulate cortex mediated communication among Dorsal PM regions. Finally, the distinction between PMN subsystems is functionally relevant: whereas both Dorsal and Ventral PM connectivity tracked the movie content, only Ventral PM connections increased in strength at event transitions and appeared sensitive to episodic memory. Overall, these findings provide a model of PMN pathways and reveal distinct functional roles of intranetwork subsystems associated with event cognition.","link":"https://doi.org/10.1016/j.neuroimage.2021.118075","hasOSF":null,"github":"http://www.thememolab.org/paper-camcan-pmn/"},{"title":"Deconstructing the posterior medial episodic network","authors":"Ritchey, M.* & Cooper, R. A.*","journal":"Trends in Cognitive Sciences, 24(6), 451-465; * equal contribution","year":"2020","abstract":"Abstract: Our ability to remember or imagine specific events involves the construction of complex mental representations, a process that engages cortical and hippocampal regions in a core posterior medial (PM) brain network. Existing theoretical approaches have described the overarching contributions of the PM network, but less is known about how episodic content is represented and transformed throughout this system. Here, we review evidence of key functional interactions among PM regions and their relation to the core cognitive operations and representations supporting episodic construction. Recent demonstrations of intranetwork functional diversity are integrated with existing accounts to inform a network-based model of episodic construction, in which PM regions flexibly share and manipulate event information to support the variable phenomenology of episodic memory and simulation.","link":"https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(20)30081-4","hasOSF":null,"github":null},{"title":"Progression from feature-specific brain activity to hippocampal binding during episodic encoding","authors":"Cooper, R. A. & Ritchey, M.","journal":"Journal of Neuroscience, 40(8), 1701-1709","year":"2020","abstract":"Abstract: The hallmark of episodic memory is recollecting multiple perceptual details tied to a specific spatial-temporal context. To remember an event, it is therefore necessary to integrate such details into a coherent representation during initial encoding. Here we tested how the brain encodes and binds multiple, distinct kinds of features in parallel, and how this process evolves over time during the event itself. We analyzed data from 27 human subjects (16 females, 11 males) who learned a series of objects uniquely associated with a color, a panoramic scene location, and an emotional sound while fMRI data were collected. By modeling how brain activity relates to memory for upcoming or just-viewed information, we were able to test how the neural signatures of individual features as well as the integrated event changed over the course of encoding. We observed a striking dissociation between early and late encoding processes: left inferior frontal and visuo-perceptual signals at the onset of an event tracked the amount of detail subsequently recalled and were dissociable based on distinct remembered features. In contrast, memory-related brain activity shifted to the left hippocampus toward the end of an event, which was particularly sensitive to binding item color and sound associations with spatial information. These results provide evidence of early, simultaneous feature-specific neural responses during episodic encoding that predict later remembering and suggest that the hippocampus integrates these features into a coherent experience at an event transition.","link":"https://www.jneurosci.org/content/40/8/1701","hasOSF":null,"github":"http://www.thememolab.org/paper-bindingfmri/"},{"title":"A database of news videos for investigating the dynamics of emotion and memory","authors":"Samide, R., Cooper, R. A., & Ritchey, M.","journal":"Behavior Research Methods, 52, 1469-1479","year":"2020","abstract":"Abstract: Emotional experiences are known to be both perceived and remembered differently from non-emotional experiences, often leading to heightened encoding of salient visual details and subjectively vivid recollection. The vast majority of previous studies have used static images to investigate how emotional event content modulates cognition, yet natural events unfold over time. Therefore, little is known about how emotion dynamically modulates continuous experience. Here, we report a norming study wherein we develop a new stimulus set of 126 emotionally negative, positive, and neutral videos depicting real-life news events. Participants continuously rated the valence of each video during its presentation and judged the overall emotional intensity and valence at the end of each video. In a subsequent memory test, participants reported how vividly they could recall the video details and estimated each video?s duration. We report data on the affective qualities and subjective memorability of each video. The results replicate the well established effect that emotional experiences are more vividly remembered than non-emotional experiences. Importantly, this novel stimulus set will facilitate research into the temporal dynamics of emotional processing and memory.","link":"https://link.springer.com/article/10.3758/s13428-019-01327-w","hasOSF":null,"github":"http://www.thememolab.org/paper-videonorming/"},{"title":"Cortico-hippocampal network connections support the multidimensional quality of episodic memory","authors":"Cooper, R. A. & Ritchey, M.","journal":"eLife, 8:e45591","year":"2019","abstract":"Abstract: Episodic memories reflect a bound representation of multimodal features that can be reinstated with varying levels of precision. Yet little is known about how brain networks involved in memory, including the hippocampus and posterior-medial (PM) and anterior-temporal (AT) cortical systems, functionally interact to support the quality and the content of recollection. Participants learned color, spatial, and emotion associations of objects, later reconstructing the visual features using a continuous color spectrum and 360-degree panorama scenes. Behaviorally, dependencies in memory were observed for the gist but not precision of these event associations. Supporting this integration, hippocampus, AT, and PM regions showed increased inter-network connectivity and reduced modularity during retrieval compared to encoding. These network connections, particularly to hippocampus, tracked a multidimensional, continuous measure of objective memory quality. Moreover, distinct patterns of connectivity tracked item color precision and spatial memory precision. These findings demonstrate not only how hippocampal-cortical connections reconfigure during episodic retrieval, but how such dynamic interactions might flexibly support the multidimensional quality of remembered events.","link":"https://elifesciences.org/articles/45591","hasOSF":null,"github":"http://www.thememolab.org/paper-orbitfmri/"},{"title":"Memories fade: The relationship between memory vividness and remembered visual salience","authors":"Cooper, R. A. , Kensinger, E. A., & Ritchey, M.","journal":"Psychological Science, 30(5), 657-668","year":"2019","abstract":"Abstract: Past events, particularly emotional experiences, are often vividly recollected. However, it remains unclear how qualitative information, such as low-level visual salience, is reconstructed and how the precision and bias of this information relates to subjective memory vividness. Here, we tested whether remembered visual salience contributes to vivid recollection. In three experiments, participants studied emotionally negative and neutral images that varied in luminance and color saturation and reconstructed the visual salience of each image in a subsequent test. Results revealed, unexpectedly, that memories were recollected as less visually salient than they were encoded, demonstrating a novel ?memory fading? effect, whereas negative emotion increased subjective memory vividness and the precision with which visual features were encoded. Finally, memory vividness tracked both the precision and remembered salience (bias) of visual information. These findings provide evidence that low-level visual information fades in memory and contributes to the experience of ?vivid? recollection.","link":"https://journals.sagepub.com/doi/10.1177/0956797619836093","hasOSF":"https://osf.io/nqbs2/","github":null},{"title":"Exploring the neurocognitive basis of episodic recollection in autism","authors":"Cooper, R. A. & Simons, J. S.","journal":"Psychonomic Bulletin & Review, 26, 163-181","year":"2019","abstract":"Abstract: Increasing evidence indicates that the subjective experience of recollection is diminished in autism spectrum disorder (ASD) compared to neurotypical individuals. The neurocognitive basis of this difference in how past events are re-experienced has been debated and various theoretical accounts have been proposed to date. Although each existing theory may capture particular features of memory in ASD, recent research questions whether any of these explanations are alone sufficient or indeed fully supported. This review first briefly considers the cognitive neuroscience of how episodic recollection operates in the neurotypical population, informing predictions about the encoding and retrieval mechanisms that might function atypically in ASD. We then review existing research on recollection in ASD, which has often not distinguished between different theoretical explanations. Recent evidence suggests a distinct difficulty engaging recollective retrieval processes, specifically the ability to consciously reconstruct and monitor a past experience, which is likely underpinned by altered functional interactions between neurocognitive systems rather than brain region-specific or process-specific dysfunction. This integrative approach serves to highlight how memory research in ASD may enhance our understanding of memory processes and networks in the typical brain. We make suggestions for future research that are important for further specifying the neurocognitive basis of episodic recollection in ASD and linking such difficulties to social developmental and educational outcomes.","link":"https://link.springer.com/article/10.3758/s13423-018-1504-z","hasOSF":null,"github":null},{"title":"Social conformity in autism","authors":"Lazzaro, S. C., Weidinger, L., Cooper, R. A., Baron-Cohen, S., Moutsiana, C., & Sharot, T.","journal":"Journal of Autism and Developmental Disorders, 49, 1304-1315","year":"2019","abstract":"Abstract: Humans are extremely susceptible to social influence. Here, we examine whether this susceptibility is altered in autism, a condition characterized by social difficulties. Autistic participants (N = 22) and neurotypical controls (N = 22) completed a memory test of previously seen words and were then exposed to answers supposedly given by four other individuals. Autistic individuals and controls were as likely to alter their judgements to align with inaccurate responses of group members. These changes reflected both temporary judgement changes (public conformity) and long-lasting memory changes (private conformity). Both groups were more susceptible to answers believed to be from other humans than from computer algorithms. Our results suggest that autistic individuals and controls are equally susceptible to social influence when reporting their memories.","link":"https://link.springer.com/article/10.1007/s10803-018-3809-1","hasOSF":null,"github":null},{"title":"Reduced hippocampal functional connectivity during episodic memory retrieval in autism","authors":"Cooper, R. A., Richter, F. R., Bays, P. M., Plaisted-Grant, K. C., Baron-Cohen, S., & Simons, J. S.","journal":"Cerebral Cortex , 27(2), 888-902.","year":"2017","abstract":"Abstract: Increasing recent research has sought to understand the recollection impairments experienced by individuals with autism spectrum disorder (ASD). Here, we tested whether these memory deficits reflect a reduction in the probability of retrieval success or in the precision of memory representations. We also used functional magnetic resonance imaging (fMRI) to study the neural mechanisms underlying memory encoding and retrieval in ASD, focusing particularly on the functional connectivity of core episodic memory networks. Adults with ASD and typical control participants completed a memory task that involved studying visual displays and subsequently using a continuous dial to recreate their appearance. The ASD group exhibited reduced retrieval success, but there was no evidence of a difference in retrieval precision. fMRI data revealed similar patterns of brain activity and functional connectivity during memory encoding in the 2 groups, though encoding-related lateral frontal activity predicted subsequent retrieval success only in the control group. During memory retrieval, the ASD group exhibited attenuated lateral frontal activity and substantially reduced hippocampal connectivity, particularly between hippocampus and regions of the fronto-parietal control network. These findings demonstrate notable differences in brain function during episodic memory retrieval in ASD and highlight the importance of functional connectivity to understanding recollection-related retrieval deficits in this population.","link":"https://academic.oup.com/cercor/article/27/2/888/2834458","hasOSF":null,"github":null},{"title":"Eye movements reveal a dissociation between memory encoding and retrieval in adults with autism","authors":"Cooper, R. A., Plaisted-Grant, K. C., Baron-Cohen, S., & Simons, J. S.","journal":"Cognition, 159, 127-138.","year":"2017","abstract":"Abstract: People with autism spectrum disorder (ASD) exhibit subtle deficits in recollection, which have been proposed to arise from encoding impairments, though a direct link has yet to be demonstrated. In the current study, we used eye-tracking to obtain trial-specific measures of encoding (eye movement patterns) during incidental (natural viewing) and intentional (strategic) encoding conditions in adults with ASD and typical controls. Using this approach, we tested the degree to which differences in encoding might contribute to recollection impairments, or whether group differences in memory primarily emerge at retrieval. Following encoding of scenes, participants were asked to distinguish between old and similar lure scenes and provide ?remember?/?familiar? responses. Intentional encoding increased eye movements and subsequent recollection in both groups to a similar degree, but the ASD group were impaired overall at the memory task and used recollection less frequently. In controls, eye movements at encoding predicted subsequent correct responses and subsequent recollection on a trial-by-trial basis, as expected. In contrast, despite a similar pattern of eye movements during encoding in the two groups, eye movements did not predict trial-by-trial subsequent memory in ASD. Furthermore, recollection was associated with lower similarity between encoding- and retrieval-related eye movements in the ASD group compared to the control group. The eye-tracking results therefore provide novel evidence for a dissociation between encoding and recollection-based retrieval in ASD.","link":"https://www.sciencedirect.com/science/article/pii/S0010027716302852","hasOSF":null,"github":null},{"title":"Distinct neural mechanisms underlie the success, precision, and vividness of episodic memory","authors":"Richter, F. R.*, Cooper, R. A.*, Bays, P. M., & Simons, J. S.","journal":"eLife, 5:e18260; * equal contribution","year":"2016","abstract":"Abstract: A network of brain regions have been linked with episodic memory retrieval, but limited progress has been made in identifying the contributions of distinct parts of the network. Here, we utilized continuous measures of retrieval to dissociate three components of episodic memory: retrieval success, precision, and vividness. In the fMRI scanner, participants encoded objects that varied continuously on three features: color, orientation, and location. Participants\u2019 memory was tested by having them recreate the appearance of the object features using a continuous dial, and continuous vividness judgments were recorded. Retrieval success, precision, and vividness were dissociable both behaviorally and neurally: successful versus unsuccessful retrieval was associated with hippocampal activity, retrieval precision scaled with activity in the angular gyrus, and vividness judgments tracked activity in the precuneus. The ability to dissociate these components of episodic memory reveals the benefit afforded by measuring memory on a continuous scale, allowing functional parcellation of the retrieval network.","link":"https://doi.org/10.7554/eLife.18260","hasOSF":null,"github":null},{"title":"Reality monitoring and metamemory in adults with autism spectrum conditions","authors":"Cooper, R. A., Plaisted-Grant, K. C., Baron-Cohen, S., & Simons, J. S.,","journal":"Journal of Autism and Developmental Disorders, 46(6), 2186-2198.","year":"2016","abstract":"Abstract: Studies of reality monitoring (RM) often implicate medial prefrontal cortex (mPFC) in distinguishing internal and external information, a region linked to autism-related deficits in social and self-referential information processing, executive function, and memory. This study used two RM conditions (self-other; perceived-imagined) to investigate RM and metamemory in adults with autism. The autism group showed a deficit in RM, which did not differ across source conditions, and both groups exhibited a self-encoding benefit on recognition and source memory. Metamemory for perceived-imagined information, but not for self-other information, was significantly lower in the autism group. Therefore, reality monitoring and metamemory, sensitive to mPFC function, appear impaired in autism, highlighting a difficulty in remembering and monitoring internal and external details of past events.","link":"https://doi.org/10.1007/s10803-016-2749-x","hasOSF":null,"github":null},{"title":"Impaired recollection of visual scene details in adults with autism spectrum conditions","authors":"Cooper, R. A., Plaisted-Grant, K. C., Hannula, D. E., Ranganath, C., Baron-Cohen, S., & Simons, J. S.","journal":"Journal of Abnormal Psychology, 124(3), 565-575.","year":"2015","abstract":"Abstract: Subtle memory deficits observed in autism spectrum conditions (ASC) have often been characterized as reflecting impaired recollection and it has been proposed that a relational binding deficit may underlie the recollection impairment. However, subjective recollection and relational binding have not been measured within the same task in ASC to date and it is unclear whether a relational binding deficit can provide a full account of recollection impairments in ASC. Relational memory has also not been compared with item memory when the demands of the 2 tasks are comparable. To assess recollection, relational memory, and item memory within a single task in ASC, 24 adults with ASC and 24 typically developed adults undertook a change detection memory task that assessed recollection of item-specific and spatial details. Participants studied rendered indoor and outdoor scenes and, in a subsequent recognition memory test, distinguished scenes that had not changed from those that had either undergone an item change (a different item exemplar) or a relational (spatial) change, which was followed by a subjective recollection judgment. The ASC group identified fewer item changes and spatial changes, to a similar degree, which was attributable to a specific reduction in recollection-based recognition relative to the control group. These findings provide evidence that recollection deficits in ASC may not be driven entirely by a relational binding deficit.","link":"http://psycnet.apa.org/record/2015-28403-001","hasOSF":null,"github":null}]')},23:function(e,t,i){e.exports=i(41)},28:function(e,t,i){},29:function(e,t,i){},39:function(e,t,i){},41:function(e,t,i){"use strict";i.r(t);var n=i(0),a=i.n(n),r=i(7),o=i.n(r),s=(i(28),i(2)),l=(i(29),i(1));var c=Object(l.a)("img",{target:"epzjsch0"})({name:"ijs0sf",styles:"width:100vw;object-fit:cover;position:relative;border-bottom:2px solid black;"}),d=Object(l.a)("div",{target:"epzjsch1"})({name:"rcvnjg",styles:'font-size:4rem;line-height:1;font-family:"Montserrat",sans-serif;position:absolute;top:4vh;left:10vw;padding-top:10vh;height:20vh;width:80vw;text-align:center;'}),m=function(e){var t=e.bigScreen,i=Object(s.useMediaQuery)({query:"(max-width: 768px)"});return a.a.createElement("div",{id:"home"},a.a.createElement(c,{style:i?{height:"20vh"}:{height:"50vh"},src:"./img/toppic.jpg",alt:""}),a.a.createElement(d,{style:i?{fontSize:"2.5rem",paddingTop:"5vh"}:t?{fontSize:"7vh"}:{}},"Rose Cooper, PhD"))},h=i(3);var u=Object(l.a)("div",{target:"es7g2wq0"})({name:"1d896py",styles:"display:flex;flex:1 1 0px;justify-content:center;align-items:center;"}),p=Object(l.a)("div",{target:"es7g2wq1"})({name:"itlcgp",styles:"width:100vw;height:10vh;margin-top:-10vh;background:rgba(255,255,255,0.7);position:sticky;top:0px;display:flex;justify-content:space-between;align-items:center;z-index:50;text-align:center;font-size:16px;"}),g=Object(l.a)("div",{target:"es7g2wq2"})({name:"189vjqg",styles:'font-size:1.5em;font-family:"Montserrat",sans-serif;color:black;padding-right:40px;cursor:pointer;&:hover{color:grey;}'}),f=Object(l.a)("div",{target:"es7g2wq3"})({name:"1ks0p0m",styles:"font-size:2em;color:black;cursor:pointer;align-self:center;text-align:left;padding-left:5vw;flex:1 1 0px;display:flex;justify-content:flex-start;"}),y=Object(l.a)("div",{target:"es7g2wq4"})({name:"idy6iw",styles:'font-size:0.9em;font-family:"Montserrat",sans-serif;color:black;text-align:right;padding-right:5vw;flex:1 1 0px;'}),v=Object(l.a)("img",{target:"es7g2wq5"})({name:"yg46ee",styles:"margin:5px;width:24px;height:24px;"}),b=function(e){var t=e.bigScreen,i={width:"2.2vh",height:"2.2vh"};return a.a.createElement(p,{style:t?{fontSize:"1.8vh"}:{}},a.a.createElement(f,null,a.a.createElement("a",{href:"https://www.linkedin.com/in/rose-cooper-phd-b46b8957/",target:"_blank",rel:"noopener noreferrer"},a.a.createElement(v,{style:t?i:{},src:"./img/linkedin.png",alt:""})),a.a.createElement("a",{href:"https://twitter.com/RoseA_Cooper",target:"_blank",rel:"noopener noreferrer"},a.a.createElement(v,{style:t?i:{},src:"./img/twitter.png",alt:""})),a.a.createElement("a",{href:"https://scholar.google.co.uk/citations?hl=en&user=oJhb_0YAAAAJ&imq=Rose+Cooper&view_op=list_works",target:"_blank",rel:"noopener noreferrer"},a.a.createElement(v,{style:t?i:{},src:"./img/googlescholar.png",alt:""})),a.a.createElement("a",{href:"https://github.com/rose-cooper",target:"_blank",rel:"noopener noreferrer"},a.a.createElement(v,{style:t?i:{},src:"./img/github.png",alt:""}))),a.a.createElement(u,null,a.a.createElement(g,{onClick:h.animateScroll.scrollToTop},"Home"),a.a.createElement(h.Link,{to:"research",smooth:!0,duration:1e3},a.a.createElement(g,null,"Research")),a.a.createElement(h.Link,{to:"publications",smooth:!0,duration:1e3},a.a.createElement(g,null,"Papers")),a.a.createElement(g,null,a.a.createElement("a",{href:"./files/RCooper-CV.pdf",target:"_blank",rel:"noopener noreferrer",style:{textDecoration:"none",color:"inherit"}},"CV"))),a.a.createElement(y,null,"rose.cooper@bc.edu"))};var w=Object(l.a)("img",{target:"edz47jn0"})({name:"10uzhcy",styles:"border-radius:50%;border-color:black;border-width:0px;border-style:solid;object-fit:cover;position:absolute;left:5%;top:15%;width:75%;height:75%;max-width:600px;max-height:600px;"}),x=Object(l.a)("div",{target:"edz47jn1"})({name:"7pra2c",styles:'position:relative;width:60%;flex:0 0 40%;display:block;&:after{content:"";display:block;padding-bottom:100%;}'}),k=function(e){var t=e.mobile;return a.a.createElement(x,{style:t?{width:"80%",left:"0%",marginBottom:"10%"}:{}},a.a.createElement(w,{style:t?{width:"80%",height:"80%",left:"10%"}:{},src:"./img/profile.jpeg",alt:""}))};var j=Object(l.a)("div",{target:"e5ie1cc0"})({name:"2svma",styles:"display:flex;flex-direction:column;align-items:flex-start;justify-content:space-around;flex:0 0 60%;"}),E=Object(l.a)("div",{target:"e5ie1cc1"})({name:"1oc3n6x",styles:"font-size:1.2rem;color:black;word-wrap:normal;display:block;white-space:pre-line;line-height:1.5;text-align:left;font-weight:600;"}),S=Object(l.a)("div",{target:"e5ie1cc2"})({name:"kso09t",styles:"font-size:1.2rem;color:black;word-wrap:normal;display:block;white-space:pre-line;line-height:1.5;text-align:left;margin-top:2rem;font-style:italic;"}),A=function(e){var t=e.mobile,i=e.bigScreen,n={fontSize:"2.2vh"};return a.a.createElement(j,{style:t?{paddingLeft:"5vw"}:{}},a.a.createElement(E,{style:i?n:{}},"2017 - present\n  Postdoctoral Researcher, Boston College\n\n  2013-2017\n  PhD Psychology, University of Cambridge"),a.a.createElement(S,{style:i?n:{}},"Cognitive neuroscientist asking how the brain represents our personal past"))};var O=Object(l.a)("div",{target:"e1k25wkp0"})({name:"17pttls",styles:"width:70vw;position:relative;display:flex;justify-content:center;align-items:center;margin-top:-5vh;"}),z=Object(l.a)("div",{target:"e1k25wkp1"})({name:"11tmttj",styles:"width:100vw;padding-top:10vh;display:flex;justify-content:center;align-items:center;margin-bottom:10vh;"}),C=function(e){var t=e.mobile,i=e.bigScreen;return a.a.createElement(z,null,a.a.createElement(O,{style:t?{flexDirection:"column",marginLeft:"10vw",marginRight:"10vw"}:{}},a.a.createElement(k,{mobile:t}),a.a.createElement(A,{bigScreen:i,mobile:t})))};var R=Object(l.a)("img",{target:"e1wn65zd0"})({name:"6isew7",styles:"width:50vh;height:35vh;margin-right:5vw;object-fit:contain;position:relative;max-width:90vw;"}),M=function(e){var t=e.source,i=e.mobile,n=e.portrait,r=e.bigScreen,o=Object(s.useMediaQuery)({query:"(min-height: 1000px)"}),l=t;return a.a.createElement(R,{style:i?{marginRight:"0vw"}:r?{}:n||o?{width:"30vw",height:"25vw"}:{},src:l,alt:""})};var q=Object(l.a)("div",{target:"e1mzpn4w0"})({name:"1d18bzd",styles:"font-size:1rem;color:black;word-wrap:normal;display:block;white-space:pre-line;line-height:1.5;text-align:justify;text-justify:inter-word;"}),P=function(e){var t=e.text,i=e.mobile,n=e.bigScreen;return a.a.createElement(q,{style:i?{marginTop:"5vh"}:n?{fontSize:"1.8vh"}:{}},t)};var D=Object(l.a)("div",{target:"e14fz4io0"})({name:"1uymgx",styles:"display:flex;flex-direction:row;justify-content:space-evenly;align-items:center;width:100%;margin-top:10vh;"}),T=function(e){var t=e.mobile,i=e.bigScreen,n=e.portrait;return a.a.createElement(D,{style:t?{flexDirection:"column"}:{}},a.a.createElement(M,{bigScreen:i,portrait:n,mobile:t,source:"./img/brain.png"}),a.a.createElement(P,{bigScreen:i,mobile:t,text:"Remembering the past and imagining the future engages a large scale network of brain regions, known as the default network. Using magnetic resonance imaging, my work investigates how functional activity and connectivity of this network shape our ability to perceive and recall unique visuospatial events. My research is particularly focused on connections between medial temporal and parietal brain regions and how their communication supports a context-based hierarchy of events in the brain. I am also interested in how the pattern of functional connections within the default network explains memory idiosyncrasies and individual differences in memory content."}))};var F=Object(l.a)("img",{target:"eyo66mr0"})({name:"1jl1sm9",styles:"width:50vh;height:35vh;object-fit:contain;position:relative;margin-left:5vw;max-width:90vw;"}),_=function(e){var t=e.source,i=e.mobile,n=e.portrait,r=e.bigScreen,o=Object(s.useMediaQuery)({query:"(min-height: 1000px)"}),l=t;return a.a.createElement(F,{style:i?{marginLeft:"0vw"}:r?{}:n||o?{width:"30vw",height:"25vw"}:{},src:l,alt:""})};var B=Object(l.a)("div",{target:"e1auc01u0"})({name:"1bdpuja",styles:"display:flex;flex-direction:row;justify-content:space-evenly;align-items:center;width:100%;"}),I=function(e){var t=e.mobile,i=e.bigScreen,n=e.portrait;return a.a.createElement(B,{style:t?{flexDirection:"column-reverse"}:{}},a.a.createElement(P,{bigScreen:i,mobile:t,text:"When we remember an event, such as dinner with friends or a hike through a national park, we mentally piece together the diverse features of our original experience \u2014 the sights, sounds, conversations, thoughts and feelings attached to that moment. Memory is more like a jigsaw puzzle than a video player: remembering one detail helps us to fit the others in place. But, the type of information we recall and the accuracy with which we do so varies considerably between experiences and from one person to another. My doctoral research explored how memory for contextual information differs in autism. My postdoctoral research uses multimodal, naturalistic paradigms to test how we integrate and reconstruct visuospatial features of our environment, and how those features influence our subjective experience of the past."}),a.a.createElement(_,{bigScreen:i,sportrait:n,mobile:t,source:"./img/behaviour.jpg"}))};var J=Object(l.a)("div",{target:"e10ha1ia0"})({name:"1v1ca16",styles:"width:70vw;display:flex;flex-direction:column;justify-content:space-between;align-items:center;"}),H=function(e){var t=e.mobile,i=e.bigScreen,n=e.portrait;return a.a.createElement(J,null,a.a.createElement(I,{portrait:n,bigScreen:i,mobile:t}),a.a.createElement(T,{portrait:n,bigScreen:i,mobile:t}))};var N=Object(l.a)("div",{target:"e1yedbgz0"})({name:"1nemsxy",styles:"width:100vw;background:white;position:relative;display:flex;flex-direction:column;justify-content:space-evenly;align-items:center;padding-top:10vh;margin-bottom:5vh;margin-top:-10vh;"}),L=function(e){var t=e.mobile,i=e.bigScreen,n=e.portrait;return a.a.createElement("div",{id:"research"},a.a.createElement(N,{style:t?{marginTop:"0%"}:{}},a.a.createElement(H,{portrait:n,bigScreen:i,mobile:t})))},W=i(8),K=(i(39),i(22));var V=Object(l.a)("div",{target:"ej4p94z0"})({name:"1d04vzq",styles:"margin:0;position:relative;width:80%;display:flex;flex-direction:column;justify-content:flex-start;align-items:flex-start;line-height:1.5;"}),Q=Object(l.a)("div",{target:"ej4p94z1"})({name:"29mwx",styles:"font-size:0.95em;text-align:left;width:100%;font-weight:bold;cursor:pointer;"}),G=Object(l.a)("div",{target:"ej4p94z2"})({name:"qzcnhq",styles:"font-size:0.95em;text-align:left;width:90%;font-weight:300;align-self:flex-start;cursor:pointer;"}),U=Object(l.a)("h4",{target:"ej4p94z3"})({name:"1j8su4w",styles:"font-size:0.9em;font-weight:300;"}),X=Object(l.a)("div",{target:"ej4p94z4"})({name:"5b7f7n",styles:"width:50vw;padding:2vh;position:relative;display:flex;justify-content:space-evenly;align-items:flex-start;background-color:white;overflow:hidden;text-align:justify;text-justify:inter-word;line-height:1.5;cursor:pointer;"}),Y=Object(l.a)("img",{target:"ej4p94z5"})({name:"1mcru9d",styles:"position:absolute;width:22px;height:22px;right:0px;top:0px;z-index:1;cursor:pointer;"}),$=Object(l.a)("img",{target:"ej4p94z6"})({name:"11aen7v",styles:"position:absolute;width:20px;height:20px;right:24px;top:1px;z-index:1;"}),Z=Object(l.a)("img",{target:"ej4p94z7"})({name:"341bgf",styles:"position:absolute;width:20px;height:20px;top:1px;right:-24px;z-index:1;"}),ee=Object(l.a)("i",{target:"ej4p94z8"})({name:"xglfec",styles:"position:absolute;width:24px;height:24px;top:0px;right:-24px;z-index:1;"}),te=Object(l.a)("div",{target:"ej4p94z9"})({name:"w87vzs",styles:"width:10%;font-size:1.3em;border-right:3px solid black;margin-right:1rem;display:flex;justify-content:center;align-items:center;"}),ie=Object(l.a)("div",{target:"ej4p94z10"})({name:"k20myz",styles:"width:100%;font-size:1.2em;line-height:2;border-bottom:3px solid black;display:flex;justify-content:flexStart;align-items:center;"}),ne=Object(l.a)("div",{target:"ej4p94z11"})({name:"539k0z",styles:"width:70vw;position:relative;display:flex;justify-content:center;flex-direction:row;min-height:10vh;margin-bottom:10px;"}),ae=function(e){var t=e.data,i=e.mobile,r=e.prevPaper,o=Object(n.useState)(!1),s=Object(W.a)(o,2),l=s[0],c=s[1],d=function(){c(!l)},m=function(){switch(t.year){case"2015":case"2019":return"#448AFF";case"2016":case"2020":return"#00BFA5";case"2017":case"2021":return"#f80759";default:m="black"}}(),h={borderColor:m};if(null!=r&&r.year===t.year)var u=!0;return a.a.createElement(ne,{style:i?{flexDirection:"column"}:{}},i&&!u?a.a.createElement(ie,{style:h},t.year):i&&u?a.a.createElement("div",{style:{height:"3vh"}}):a.a.createElement(te,{style:h},t.year),a.a.createElement(V,{style:i?{width:"100%"}:{}},a.a.createElement(Y,{onClick:function(){return d()},src:"./img/expand.png",alt:""}),a.a.createElement("a",{href:t.link,target:"_blank",rel:"noopener noreferrer"},a.a.createElement($,{src:"./img/link.png",alt:"",target:"_blank",rel:"noopener noreferrer"})),null!=t.hasOSF?a.a.createElement(ee,null,a.a.createElement("a",{href:t.hasOSF,target:"_blank",rel:"noopener noreferrer",style:{textDecoration:"none",color:"inherit"}},a.a.createElement("i",{className:"ai ai-osf",style:{fontSize:"24px"}}))):null,null!=t.github?a.a.createElement("a",{href:t.github,alt:"",target:"_blank",rel:"noopener noreferrer"},a.a.createElement(Z,{src:"./img/github.png",alt:""})):null,a.a.createElement(G,{style:i?{width:"85%"}:{},onClick:function(){return d()}},t.authors),a.a.createElement(G,{onClick:function(){return d()}},t.journal),a.a.createElement(Q,{onClick:function(){return d()}},t.title),a.a.createElement(K.Collapse,{isOpened:l},a.a.createElement(X,{onClick:function(){return d()},style:i?{width:"90%"}:{}},a.a.createElement(U,null,t.abstract)))))},re=i(13);var oe=Object(l.a)("div",{target:"ekv58kn0"})({name:"weljyw",styles:"padding-top:10vh;width:100vw;background:white;position:relative;display:flex;flex-direction:column;justify-content:space-around;align-items:center;line-height:1;font-size:16px;"}),se=function(e){var t=e.mobile,i=e.bigScreen,n=re.map((function(e,i){var n=re[i-1];return a.a.createElement(ae,{prevPaper:n,mobile:t,key:e.title,data:e})}));return a.a.createElement("div",{id:"publications"},a.a.createElement(oe,{style:t?{paddingTop:"5vh"}:i?{fontSize:"1.8vh"}:{}},n))};var le=Object(l.a)("div",{target:"ey719qs0"})({name:"1uxuz7g",styles:"height:5vh;width:100vw;background-color:#313131;display:block;margin-top:10vh;"}),ce=Object(l.a)("div",{target:"ey719qs1"})({name:"1sxehr0",styles:"line-height:2.5;text-align:center;font-size:0.8rem;color:white;"}),de=function(){return a.a.createElement(le,null,a.a.createElement(ce,null,"\xa9 Rose Cooper 2021"))};var me=Object(l.a)("div",{target:"eucs6yk0"})({name:"1e6yl0p",styles:"position:fixed;display:flex;flex-direction:column;justify-content:space-evenly;align-items:center;top:2vh;left:2vw;width:7vh;height:7vh;background-color:transparent;border-radius:50%;z-index:98;cursor:pointer;"}),he=Object(l.a)("div",{target:"eucs6yk1"})({name:"13hztma",styles:"position:fixed;top:0vh;left:0vw;width:50vw;height:100vh;background:rgba(255,255,255,0.85);border-right:1px solid black;z-index:50;padding-top:10vh;display:flex;flex-direction:column;justify-content:space-around;align-items:center;transition:transform 300ms ease-in-out;"}),ue=Object(l.a)("div",{target:"eucs6yk2"})({name:"1c46cjh",styles:'font-size:0.9rem;font-family:"Montserrat",sans-serif;color:black;'}),pe=Object(l.a)("div",{target:"eucs6yk3"})({name:"dq9ahf",styles:'font-size:1.5rem;font-family:"Montserrat",sans-serif;color:black;cursor:pointer;'}),ge=Object(l.a)("img",{target:"eucs6yk4"})({name:"yg46ee",styles:"margin:5px;width:24px;height:24px;"}),fe=Object(l.a)("div",{target:"eucs6yk5"})({name:"1t17fsv",styles:"position:relative;display:flex;flex-direction:row;align-items:flex-start;"}),ye=Object(l.a)("div",{target:"eucs6yk6"})({name:"q7qwin",styles:"position:relative;width:70%;height:0px;border-radius:5px;border:2px solid black;background-color:black;transform-origin:1px;transition:all 300ms ease-in-out;"}),ve=Object(l.a)("div",{target:"eucs6yk7"})({name:"1hrj9nk",styles:"width:100vw;height:100vh;position:fixed;top:0px;left:0px;background-color:transparent;opacity:0.2;z-index:20;transition:transform 300ms ease-in-out;"}),be=function(){var e=Object(n.useState)(!1),t=Object(W.a)(e,2),i=t[0],r=t[1],o=function(){r(!i)};return a.a.createElement(a.a.Fragment,null,a.a.createElement(ve,{style:i?{}:{transform:"translateX(-120%)"},onClick:function(){return o()}}),a.a.createElement(me,{open:i,onClick:function(){return o()}},a.a.createElement(ye,{style:i?{transform:"rotate(46deg)"}:{}}),a.a.createElement(ye,{style:i?{transform:"translateX(-100%)",opacity:"0"}:{}}),a.a.createElement(ye,{style:i?{transform:"rotate(-46deg)"}:{}})),a.a.createElement(he,{style:i?{}:{transform:"translateX(-120%)"}},a.a.createElement(pe,{onClick:h.animateScroll.scrollToTop},"Home"),a.a.createElement(h.Link,{to:"research",smooth:!0,duration:1e3},a.a.createElement(pe,null,"Research")),a.a.createElement(h.Link,{to:"publications",smooth:!0,duration:1e3},a.a.createElement(pe,null,"Papers")),a.a.createElement(pe,null,a.a.createElement("a",{href:"./files/RCooper-CV.pdf",target:"_blank",rel:"noopener noreferrer",style:{textDecoration:"none",color:"inherit"}},"CV")),a.a.createElement(fe,null,a.a.createElement("a",{href:"https://www.linkedin.com/in/rose-cooper-phd-b46b8957/",target:"_blank",rel:"noopener noreferrer"},a.a.createElement(ge,{src:"./img/linkedin.png",alt:""})),a.a.createElement("a",{href:"https://twitter.com/RoseA_Cooper",target:"_blank",rel:"noopener noreferrer"},a.a.createElement(ge,{src:"./img/twitter.png",alt:""})),a.a.createElement("a",{href:"https://scholar.google.co.uk/citations?hl=en&user=oJhb_0YAAAAJ&imq=Rose+Cooper&view_op=list_works",target:"_blank",rel:"noopener noreferrer"},a.a.createElement(ge,{src:"./img/googlescholar.png",alt:""})),a.a.createElement("a",{href:"https://github.com/rose-cooper",target:"_blank",rel:"noopener noreferrer"},a.a.createElement(ge,{src:"./img/github.png",alt:""}))),a.a.createElement(ue,null,"rose.cooper@bc.edu"),a.a.createElement("div",{style:{height:"1vh"}}),a.a.createElement("div",{style:{height:"1vh"}})))};var we=function(){var e=Object(s.useMediaQuery)({query:"(max-width: 1024px)"}),t=Object(s.useMediaQuery)({query:"(min-width: 1600px)"}),i=Object(s.useMediaQuery)({query:"(orientation: portrait)"});return a.a.createElement("div",{className:"App"},a.a.createElement(m,{bigScreen:t}),e?a.a.createElement(be,null):a.a.createElement(b,{bigScreen:t}),a.a.createElement(C,{bigScreen:t,mobile:e}),a.a.createElement(L,{portrait:i,bigScreen:t,mobile:e}),a.a.createElement(se,{bigScreen:t,mobile:e}),a.a.createElement(de,null))};Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));o.a.render(a.a.createElement(a.a.StrictMode,null,a.a.createElement(we,null)),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})).catch((function(e){console.error(e.message)}))}},[[23,1,2]]]);
//# sourceMappingURL=main.1b481e4f.chunk.js.map